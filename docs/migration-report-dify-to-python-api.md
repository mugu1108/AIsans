# 営業リスト作成システム 技術移行報告書

## 概要

本報告書は、営業リスト作成システムの内部アーキテクチャを **Dify ワークフロー構成** から **Python API 単体構成** へ移行した経緯、技術的改善点、および成果についてまとめたものです。

---

## 1. 移行の背景

### 1.1 従来のDify構成における課題

従来のシステムでは、Dify（ノーコードAIワークフロー基盤）を中心に以下の処理を行っていました：

| 処理 | Difyノード数 | 課題 |
|------|-------------|------|
| 入力解析（LLM） | 3ノード | - |
| 検索クエリ生成 | 5ノード | 固定パターンのため枯渇しやすい |
| Serper API検索 | 8ノード | ループ処理が複雑 |
| LLMクレンジング | 10ノード | プロンプト調整が困難 |
| スクレイピング | 15ノード | 並列処理の制限 |
| 重複チェック・保存 | 12ノード | GAS連携が不安定 |
| 結果整形・通知 | 8ノード | - |
| **合計** | **約61ノード** | - |

#### 主な問題点

1. **タイムアウト問題**
   - Difyワークフローには実行時間制限があり、50件を超える検索でタイムアウトが頻発
   - 特にスクレイピング処理で時間超過

2. **スケーラビリティの限界**
   - 100件以上の大量検索に対応困難
   - ループ処理の並列化に制約

3. **デバッグ・改善の困難さ**
   - 61ノードの複雑なフローは可視化が難しい
   - LLMプロンプトの微調整に都度デプロイが必要

4. **リトライ処理の限界**
   - 固定クエリパターンでは検索結果の多様性に限界
   - 失敗時の再検索でクエリが枯渇

---

## 2. 移行後のアーキテクチャ

### 2.1 システム構成図

```
┌─────────────────────────────────────────────────────────────────┐
│                        ユーザー (Slack)                          │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                  Slack Bot (TypeScript/Node.js)                  │
│                        Railway でホスト                          │
│  ・メンション検知                                                 │
│  ・入力パース（件数・キーワード抽出）                              │
│  ・Python API 呼び出し                                           │
│  ・結果通知（スレッド返信）                                       │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                   Python API (FastAPI)                           │
│                      Railway でホスト                            │
│                                                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │ QueryPool   │  │ Serper API  │  │ LLM         │              │
│  │ クエリ生成   │→│ 検索実行     │→│ クレンジング  │              │
│  │ (800+パターン)│  │             │  │ (GPT-4o)    │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│         │                                  │                     │
│         ▼                                  ▼                     │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │ Scraper     │  │ 重複チェック │  │ GAS 保存    │              │
│  │ (並列処理)   │→│ (既存DB照合) │→│ (Webhook)   │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│              Google Sheets (スプレッドシート)                     │
│                 GAS経由でデータ保存・管理                         │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 処理フロー

1. **Slack メンション受信** → Slack Bot が検知
2. **入力パース** → キーワード・件数を抽出
3. **Python API 呼び出し** → 非同期ジョブとして開始
4. **QueryPool 生成** → 800以上のクエリパターンを事前生成
5. **Serper API 検索** → バッチ単位で検索実行
6. **LLM クレンジング** → GPT-4o で企業名正規化
7. **スクレイピング** → 並列処理でお問い合わせURL取得
8. **重複チェック** → 既存スプレッドシートのドメインと照合
9. **GAS 保存** → Webhook 経由でスプレッドシートに追記
10. **Slack 通知** → 完了メッセージをスレッドに返信

---

## 3. 技術的改善点

### 3.1 QueryPool 方式（v3）

従来の固定クエリパターンから、動的なクエリプール方式に刷新しました。

#### 改善内容

```
入力: 「東京 IT企業」

従来: 固定5パターン程度
  - "東京 IT企業"
  - "東京 IT企業 一覧"
  - "東京 システム開発"
  ...

改善後: 800+ パターン自動生成
  地域バリエーション × 業種バリエーション × 属性サフィックス

  地域: 東京, 東京都, 都内, 首都圏, 23区...
  業種: IT企業, IT会社, システム開発, ソフトウェア開発, SIer...
  属性: 一覧, リスト, おすすめ, 人気, 企業情報...
```

#### 効果
- リトライ時でもクエリが枯渇しない
- 多様な検索結果を取得可能
- ラウンドごとに未使用クエリをバッチ取得

### 3.2 LLM クレンジング（v7）

企業名の正規化ロジックを根本から見直しました。

#### アプローチの変更

| 項目 | 従来 | 改善後 |
|------|------|--------|
| 方針 | 「ゴミを削る」 | 「法人格+社名を抽出する」 |
| 精度 | 漏れが多い | 高精度 |
| 処理 | 正規表現中心 | LLM + 正規表現のハイブリッド |

#### 具体例

```
入力: "【2024年最新】株式会社サンプル｜東京のIT企業"
従来: "【2024年最新】株式会社サンプル｜東京のIT企業" (そのまま)
改善後: "株式会社サンプル"

入力: "システム開発なら株式会社テスト - 公式サイト"
従来: "株式会社テスト - 公式サイト"
改善後: "株式会社テスト"
```

#### 追加バリデーション
- 法人格（株式会社、有限会社等）を含まない場合は除外
- 20文字以上の異常に長い企業名は除外
- ドメイン名のみ（例: example.co.jp）は除外

### 3.3 動的リトライ回数

目標件数に応じてリトライ回数を自動調整します。

| 目標件数 | リトライ回数 |
|----------|-------------|
| 〜50件 | 3回 |
| 51〜100件 | 5回 |
| 101〜200件 | 7回 |
| 201件〜 | 10回 |

### 3.4 スクレイピング後クレンジング

スクレイピング完了後に再度クレンジングを実行し、最終的な企業名品質を担保します。

```
検索結果 → LLMクレンジング → スクレイピング → 再クレンジング → 保存
```

---

## 4. 成果

### 4.1 処理能力の向上

| 項目 | 従来（Dify） | 改善後（Python API） |
|------|-------------|---------------------|
| 最大処理件数 | 50件 | **500件** |
| 処理時間（100件） | タイムアウト | 約3〜5分 |
| 成功率 | 約60% | **約95%** |

### 4.2 安定性の向上

- タイムアウトエラーの解消
- リトライ処理の信頼性向上
- エラー時の詳細ログ出力

### 4.3 保守性の向上

- コードベースでの管理（Git履歴で変更追跡可能）
- ユニットテスト可能な構造
- プロンプト調整が容易（コード変更→即デプロイ）

### 4.4 コスト効率

- Difyのノード実行コストを削減
- LLM API呼び出しの最適化（バッチ処理）

---

## 5. 拡張性

### 5.1 Dify ハイブリッドモード（オプション）

将来的な要件に対応するため、Difyとの併用モードも実装済みです。

```
環境変数: WORKFLOW_MODE

- python      : Python API 単体（現在のデフォルト）
- dify_hybrid : Dify + Python API の組み合わせ
- dify_legacy : 従来の Dify のみ
```

#### ハイブリッドモードの構成

Difyは入力解析と結果整形のみ担当（5〜6ノード）:

```
[入力パース(LLM)] → [HTTP Request: Python API] → [結果整形] → [出力]
```

重い処理（検索・スクレイピング・保存）は引き続きPython APIが担当。

---

## 6. 技術スタック

| レイヤー | 技術 | 用途 |
|----------|------|------|
| フロントエンド | Slack | ユーザーインターフェース |
| Slack Bot | TypeScript / Node.js | メンション検知・通知 |
| API | Python / FastAPI | 検索・クレンジング・スクレイピング |
| LLM | OpenAI GPT-4o | 企業名クレンジング |
| 検索 | Serper API | Google検索結果取得 |
| データ保存 | Google Sheets + GAS | スプレッドシート管理 |
| ホスティング | Railway | Bot・API のデプロイ |
| データベース | PostgreSQL (Supabase) | ログ・設定管理 |

---

## 7. まとめ

Difyワークフロー構成からPython API単体構成への移行により、以下を実現しました：

1. **処理能力10倍向上**: 50件 → 500件
2. **安定性大幅改善**: 成功率60% → 95%
3. **保守性向上**: コードベースでの管理
4. **拡張性確保**: ハイブリッドモードで将来対応可能

今後も継続的な改善を行い、より高品質な営業リスト作成を実現してまいります。

---

## 付録: 主要コンポーネント一覧

| ファイル | 役割 |
|----------|------|
| `scraping-api/services/serper.py` | Serper API検索・QueryPool管理 |
| `scraping-api/services/llm_cleanser.py` | LLMクレンジング（v7） |
| `scraping-api/services/search_workflow.py` | 検索ワークフロー制御 |
| `scraping-api/services/scraper.py` | 並列スクレイピング |
| `scraping-api/services/gas_client.py` | GAS Webhook連携 |
| `src/index.ts` | Slack Bot エントリーポイント |
| `src/application/WorkflowOrchestrator.ts` | ワークフロー統合 |
| `src/infrastructure/python/PythonAPIClient.ts` | Python API クライアント |

---

*作成日: 2025年2月*
*AI-Shine 開発チーム*
